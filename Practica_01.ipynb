{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paquete de _Python_ [scikit-learn](http://scikit-learn.org) (_sklearn_ en lo que sigue) proporciona un marco de trabajo para el aprendizaje automático."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ilustrar el concepto de aprendizaje supervisado vamos a usar el conjunto de datos [_Car Evaluation_](http://archive.ics.uci.edu/ml/datasets/Car+Evaluation) del repositorio [UCI](http://archive.ics.uci.edu/ml/). Este conjunto de datos contiene información acerca de la idoneidad de una serie de coches, en función de los siguientes atributos:\n",
    "* _buying_: precio de compra. Posibles valores: vhigh, high, med, low.\n",
    "* _maint_: coste de mantenimiento. Posibles valores: vhigh, high, med, low.\n",
    "* _doors_: número de puertas. Posibles valores: 2, 3, 4, 5more.\n",
    "* _persons_: número de asientos. Posibles valores: 2, 4, more.\n",
    "* *lug\\_boot*: tamaño del maletero. Posibles valores: small, med, big.\n",
    "* _safety_: nivel de seguridad estimada. Posibles valores: low, med, high.\n",
    "\n",
    "La idoneidad de cada coche se indica mediante el atributo _acceptability_, que los clasifica como _unacc_, _acc_, _good_ o _vgood_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para leer los datos desde el fichero `cars.csv` que se proporciona se pueden evaluar las siguientes expresiones ([_Pandas_](http://pandas.pydata.org/) y [_NumPy_](http://www.numpy.org/) son paquetes de _Python_ para análisis de datos y cálculo científico, respectivamente):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "\n",
    "cars = pandas.read_csv('cars.csv', header=None,\n",
    "                       names=['buying', 'maint', 'doors', 'persons',\n",
    "                              'lug_boot', 'safety', 'acceptability'])\n",
    "print(cars.shape)  # Número de filas y columnas\n",
    "cars.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_sklearn_ no puede trabajar directamente con el conjunto de datos anterior, ya que asume que los valores de las variables discretas están codificadas con números enteros. Para transformar los datos a un formato adecuado ofrece diversas operaciones de preprocesamiento, entre las que se encuentra _LabelEncoder_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()  # Creamos un codificador de etiquetas\n",
    "le.fit(cars['buying'])  # Calculamos la codificación de cada valor\n",
    "print(le.classes_)\n",
    "print(le.transform(['vhigh', 'med', 'high', 'low', 'vhigh']))  # Codificamos los valores\n",
    "print(le.inverse_transform([3, 2, 0, 1, 3]))  # Descodificamos los códigos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que repetir el esquema anterior para cada columna de la tabla de datos. Además, conservaremos los codificadores de cada columna para poder usar la misma codificación con nuevos ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codificadores = []\n",
    "cars_codificado = pandas.DataFrame()\n",
    "for variable, valores in cars.iteritems():\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(valores)\n",
    "    print('Codificación de valores para {}: {}'.format(variable, le.classes_))\n",
    "    codificadores.append(le)\n",
    "    cars_codificado[variable] = le.transform(valores)\n",
    "\n",
    "cars_codificado.head(10)\n",
    "\n",
    "# Si no es necesario conservar los codificadores, la siguiente es una manera más\n",
    "# directa de codificar las variables\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# cars_codificado = cars.apply(le.fit_transform, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez codificadas las variables, es necesario separar el conjunto de datos en dos: un conjunto de entrenamiento, que se usará para generar los distintos modelos; y un conjunto de prueba, que se usará para comparar los distintos modelos.\n",
    "\n",
    "Un detalle a tener en cuenta es que la distribución de ejemplos en las distintas clases de aceptabilidad no es uniforme: hay 1210 coches (un 70.023 % del total) clasificados como inaceptables (`unacc`), 384 coches (22.222 %) clasificados como aceptables (`acc`), 69 coches ( 3.993 %) clasificados como buenos (`good`) y 65 coches ( 3.762 %) clasificados como muy buenos (`vgood`).\n",
    "\n",
    "Es conveniente, por tanto, que la separación de los ejemplos se realice de manera estratificada, es decir, intentando mantener la proporción anterior tanto en el conjunto de entrenamiento como en el de prueba.\n",
    "\n",
    "Para dividir un conjunto de datos en un subconjunto de entrenamiento y otro de prueba, _sklearn_ proporciona la función `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "print('Codificación:', codificadores[-1].classes_)\n",
    "print(cars_codificado.shape[0])  # Cantidad total de ejemplos\n",
    "print(cars_codificado['acceptability'].value_counts(\n",
    "        normalize=True, sort=False))  # Frecuencia total de cada clase de aceptabilidad\n",
    "\n",
    "cars_entrenamiento, cars_prueba = model_selection.train_test_split(\n",
    "    cars_codificado, test_size=.33, random_state=12345,\n",
    "    stratify=cars_codificado['acceptability'])\n",
    "\n",
    "# Comprobamos que el conjunto de prueba contiene el 33 % de los datos, en la misma proporción\n",
    "# con respecto a la variable objetivo\n",
    "print(cars_prueba.shape[0], 1728 * .33)\n",
    "print(cars_prueba['acceptability'].value_counts(\n",
    "        normalize=True, sort=False))\n",
    "\n",
    "# Comprobamos que el conjunto de entrenamiento contiene el resto de los datos, en la misma\n",
    "# proporción con respecto a la variable objetivo\n",
    "print(cars_entrenamiento.shape[0], 1728 * (1 - .33))\n",
    "print(cars_entrenamiento['acceptability'].value_counts(\n",
    "        normalize=True, sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar aprendizaje supervisado en _sklearn_ basta crear una instancia de la clase de objetos que implemente el modelo que se quiera utilizar (árboles de decisión, _naive_ Bayes, _kNN_, etc.).\n",
    "\n",
    "Cada una de estas instancias dispondrá de los siguientes métodos:\n",
    "* El método `fit` permite entrenar el modelo, dados __por separado__ el conjunto de ejemplos de entrenamiento y la clase de cada uno de estos ejemplos.\n",
    "* El método `predict` permite clasificar un nuevo ejemplo una vez entrenado el modelo.\n",
    "* El método `score` calcula el rendimiento del modelo, dados __por separado__ el conjunto de ejemplos de prueba y la clase de cada uno de estos ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un requisito para poder continuar es separar los conjuntos de datos `cars_entrenamiento` y `cars_prueba` en los valores de los atributos por un lado y la clasificación por otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_entrenamiento = cars_entrenamiento.loc[:, 'buying':'safety']\n",
    "clases_entrenamiento = cars_entrenamiento['acceptability']\n",
    "\n",
    "datos_prueba = cars_prueba.loc[:, 'buying':'safety']\n",
    "clases_prueba = cars_prueba['acceptability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_sklearn_ implementa los árboles de decisión clasificadores como instancias de la clase `DecisionTreeClassifier`.\n",
    "\n",
    "Desafortunadamente, son árboles de decisión binarios construidos asumiendo atributos continuos y mediante un algoritmo distinto a _ID3_, que no está implementado.\n",
    "\n",
    "En http://scikit-learn.org/stable/modules/tree.html se puede encontrar información acerca de los árboles de decisión implementados en _sklearn_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Naive_ Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_sklearn_ implementa _naive_ Bayes para atributos discretos mediante instancias de la clase `MultinomialNB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "clasif_NB = naive_bayes.MultinomialNB(alpha=1.0)  # alpha es el tamaño muestral equivalente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La utilización de la instancia construida requiere que los atributos que caracterizan los ejemplos sean binarios. Podemos transformar nuestros atributos multinomiales en atributos binarios mediante el preprocesador `OneHotEncoder` de _sklearn_.\n",
    "\n",
    "Este preprocesador permite convertir una variable con $n$ posibles valores en $n$ variables binarias mutuamente excluyentes que codifican el valor que para esa variable tiene el ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = preprocessing.OneHotEncoder(sparse = False)\n",
    "# En las expresiones siguientes, el método values proporciona los datos como un vector de\n",
    "# numpy y el método reshape lo transforma entonces a una matriz con una columna y tantas\n",
    "# filas como sea necesario. Esto debe hacerse ya que el preprocesador OneHotEncoder solo\n",
    "# trabaja con matrices.\n",
    "print(cars_codificado['buying'].values)\n",
    "print(cars_codificado['buying'].values.reshape(-1, 1))\n",
    "ohe.fit(cars_codificado['buying'].values.reshape(-1,1))\n",
    "ohe.transform(cars_codificado['buying'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = preprocessing.OneHotEncoder(sparse = False)\n",
    "# El método fit_transform realiza un ajuste a partir de una matriz de datos seguido de una\n",
    "# transformación de esos mismos datos.\n",
    "datos_entrenamiento_nb = ohe.fit_transform(datos_entrenamiento)\n",
    "datos_prueba_nb = ohe.fit_transform(datos_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya estamos en condiciones de poder entrenar el modelo _naive_ Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_NB.fit(datos_entrenamiento_nb, clases_entrenamiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes expresiones muestran las cuentas realizadas y (los logaritmos de) las probabilidades aprendidas por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clasif_NB.class_count_)\n",
    "print(clasif_NB.class_log_prior_)\n",
    "print(clasif_NB.feature_count_)\n",
    "print(clasif_NB.feature_log_prob_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `predict` devuelve la clase predicha por el modelo para un nuevo ejemplo y el método `score` el rendimiento sobre un conjunto de datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_ejemplo = ['vhigh', 'vhigh', '3', 'more', 'big', 'high']\n",
    "# Codificamos los valores de los atributos\n",
    "nuevo_ejemplo_codif = [le.transform([valor])\n",
    "                       for valor, le in zip(nuevo_ejemplo, codificadores)]\n",
    "nuevo_ejemplo_codif = numpy.reshape(nuevo_ejemplo_codif, (1, -1))\n",
    "print(nuevo_ejemplo_codif)\n",
    "# Transformamos los atributos a codificación binaria\n",
    "nuevo_ejemplo_nb = ohe.transform(nuevo_ejemplo_codif)\n",
    "print(nuevo_ejemplo_nb)\n",
    "# Predecimos la clase\n",
    "clase_nuevo_ejemplo = clasif_NB.predict(nuevo_ejemplo_nb)\n",
    "print(codificadores[-1].inverse_transform(clase_nuevo_ejemplo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la fracción de clases correctamente predichas para el conjunto de datos de prueba\n",
    "clasif_NB.score(datos_prueba_nb, clases_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_sklearn_ implementa _kNN_ como instancias de la clase `KNeighborsClassifier`. En http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html se puede encontrar una descripción de las distancias actualmente implementadas que se podrían usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "clasif_kNN = neighbors.KNeighborsClassifier(n_neighbors=5, metric='hamming')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_kNN.fit(datos_entrenamiento, clases_entrenamiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `kneighbors` permite encontrar los (índices de los) $k$ vecinos más cercanos de los ejemplos proporcionados, así como las distancias a las que se encuentran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distancias, vecinos = clasif_kNN.kneighbors(nuevo_ejemplo_codif)\n",
    "print(nuevo_ejemplo_codif)\n",
    "print(datos_entrenamiento.iloc[vecinos[0]])\n",
    "print(distancias[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `predict` devuelve la clase predicha por el modelo para un nuevo ejemplo y el método `score` el rendimiento sobre un conjunto de datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_nuevo_ejemplo = clasif_kNN.predict(nuevo_ejemplo_codif)\n",
    "print(codificadores[-1].inverse_transform(clase_nuevo_ejemplo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif_kNN.score(datos_prueba, clases_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solicitudes de admisión en guarderías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El fichero de datos `nursery.csv` proporciona un conjunto de datos acerca de la evaluación de solicitudes de admisión en guarderías, en función de los siguientes atributos:\n",
    "* _parents_, con posibles valores: usual, pretentious, great_pret.\n",
    "* *has\\_nurs*, con posibles valores: proper, less_proper, improper, critical, very_crit.\n",
    "* _form_, con posibles valores: complete, completed, incomplete, foster.\n",
    "* _children_, con posibles valores: 1, 2, 3, more.\n",
    "* _housing_, con posibles valores: convenient, less_conv, critical.\n",
    "* _finance_, con posibles valores: convenient, inconv.\n",
    "* _social_, con posibles valores: non-prob, slightly_prob, problematic.\n",
    "* _health_, con posibles valores: recommended, priority, not_recom.\n",
    "\n",
    "Los datos provienen de un sistema experto de decisión usado durante varios años de la década de los 80 en Liubliana (Eslovenia), que se desarrolló para poder proporcionar una explicación objetiva a las solicitudes rechazadas.\n",
    "\n",
    "La evaluación de cada solicitud se indica mediante el atributo _evaluation_, que los clasifica como *not\\_recom*, _recommend_, *very\\_recom*, _priority_ o *spec\\_prior*.\n",
    "\n",
    "El objetivo es aprender a partir de los datos un modelo que prediga de la mejor forma posible cómo se evaluará una solicitud de admisión a partir de los valores de los atributos anteriores. Para ello se pide seguir los siguientes pasos:\n",
    "* Leer los datos a partir del fichero `nursery.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Codificar los datos con números enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dividir el conjunto de datos en tres subconjuntos: un subconjunto `nursery_cv` (20 % de los datos) para determinar los mejores parámetros de los modelos mediante validación cruzada; un subconjunto `nursery_entrenamiento` (60 % de los datos) para entrenar los modelos con esos parámetros; un subconjunto `nursery_prueba` (20 % de los datos) para comparar los modelos a partir de su rendimiento sobre él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para cada uno de los subconjuntos anteriores, separar los datos correspondientes a los valores de los atributos de cada ejemplo de los datos correspondientes a la clasificación de cada ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dividir el subconjunto `nursery_cv` en 10 subconjuntos y usarlos para calcular mediante validación cruzada el rendimiento promedio del algoritmo _naive_ Bayes. Considerar para el tamaño muestral equivalente cada uno de los valores enteros entre 1 y 10 y determinar cuál es el que proporciona mejor rendimiento promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import naive_bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Con el mejor tamaño muestral equivalente determinado en el punto anterior, entrenar el algoritmo _naive_ Bayes con el subconjunto `nursery_entrenamiento` y calcular el rendimiento sobre el subconjunto `nursery_prueba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dividir el subconjunto `nursery_cv` en 10 subconjuntos y usarlos para calcular mediante validación cruzada el rendimiento promedio del algoritmo _kNN_. Considerar para $k$ cada uno de los valores enteros entre 1 y 10 y determinar cuál es el que proporciona mejor rendimiento promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Con el mejor $k$ determinado en el punto anterior, entrenar el algoritmo _kNN_ con el subconjunto `nursery_entrenamiento` y calcular el rendimiento sobre el subconjunto `nursery_prueba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Cuál de los dos modelos construidos en los puntos anteriores realiza mejores predicciones acerca de la evaluación de las solicitudes de admisión?\n",
    "\n",
    "__Nota__: la función `cross_val_score` del módulo `model_selection` de _sklearn_ implementa el procedimiento de validación cruzada. Admite, entre otros, los siguientes argumentos:\n",
    "* _estimator_: modelo a evaluar.\n",
    "* _X_: array con los valores de los atributos de los ejemplos.\n",
    "* _y_: array con las clasificaciones de los ejemplos.\n",
    "* _cv_: número de subconjuntos en los que dividir los datos.\n",
    "\n",
    "Devuelve un array con el rendimiento del modelo sobre cada subconjunto, una vez entrenado con los ejemplos del resto de subconjuntos.\n",
    "\n",
    "Para más información acerca de la implementación en _sklearn_ del método de validación cruzada puede consultarse http://scikit-learn.org/stable/modules/cross_validation.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Respuesta:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
